{"metadata": {"language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "pytorch-1.4.0", "display_name": "Pytorch-1.4.0", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report\n\nimport json\nimport pickle\n\nimport os\nimport moxing as mox\n\nmox.file.shift('os', 'mox')\n\nnp.random.seed(2020)\ntorch.manual_seed(2020)\n\nNUM_SAMPLES = 2001\n\ndevice = 'cuda'\n\nroot_dir = 's3://my-modelarts-xyx-010/notebook-001/'\n\ndata_dir = os.path.join(root_dir, 'data')\nmodel_dir = os.path.join(root_dir, 'model')\n\npca_path = os.path.join(model_dir, 'classifier-pca.pkl')\nmodel_path = os.path.join(model_dir, 'classifier.pt')", "metadata": {"trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v1.17.3-\nINFO:root:Using OBS-Python-SDK-3.20.7\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "def get_data(filename):\n    with open(filename, encoding='utf-8') as file:\n        return json.load(file)\n\ndef sample_feats(feats, num):\n    idx = np.arange(len(feats))\n    np.random.shuffle(idx)\n    idx = idx[:num]\n    assert len(idx) == num\n    return np.sum(feats[idx], axis=0) / num\n\ndef sample_from_record(record, num_per_sample, X, y):\n    X.append(sample_feats(record['feats'], num_per_sample).reshape(-1))\n    y.append(0 if record['name'] == 'cotton' else 1)\n\ndef repetitive_sample_from_record(record, num_samples, num_per_sample, X, y):\n    [\n        sample_from_record(record, num_per_sample, X, y)\n        for _ in range(num_samples)\n    ]\n\ndef get_id_dict(dataset):\n    id_dict = {'cotton': [], 'cotton_spandex': []}\n    for i, record in enumerate(dataset):\n        id_dict[record['name']].append(i)\n    return id_dict\n\ndef sample_dataset(dataset, num_samples, num_per_sample, balance):\n    id_dict = get_id_dict(dataset)\n    X = []\n    y = []\n    for record in dataset:\n        repetitive_sample_from_record(record, num_samples, num_per_sample, X, y)\n    a = len(id_dict['cotton'])\n    b = len(id_dict['cotton_spandex']) * 1.0\n    b = int(b)\n    print(a, b)\n    if balance and a != b:\n        if a > b:\n            diff = a - b\n            idx = np.arange(b)\n            name = 'cotton_spandex'\n        else:  # b > a\n            diff = b - a\n            idx = np.arange(a)\n            name = 'cotton'\n        np.random.shuffle(idx)\n        idx = idx[:diff]\n        [\n            repetitive_sample_from_record(\n                dataset[id_dict[name][i]],\n                num_samples, num_per_sample, X, y\n            ) for i in idx\n        ]\n    return np.array(X), np.array(y, dtype=np.int64)\n\ndef process_dataset(dataset, num_samples=NUM_SAMPLES, num_per_sample=15, balance=False, dev=0):\n    id_dict = get_id_dict(dataset)\n    for record in dataset:\n        feats = np.array(record['feat'], np.float32)\n        feats2 = []\n        for feat in feats:\n            feat[:, 0] /= 1800\n            feat[:, 2] /= 500000\n            feat = feat[:, 1:]\n            feats2.append(feat)\n        record.pop('feat')\n        feats = np.array(feats2, np.float32)\n        record['feats'] = feats  # not `feat`\n    if dev == 0:  # no dev set\n        return sample_dataset(dataset, num_samples, num_per_sample, balance)\n    else:\n        def sample_id(id_list):\n            idx = np.arange(len(id_list))\n            np.random.shuffle(idx)\n            return [id_list[i] for i in idx[:dev]], [id_list[i] for i in idx[dev:]]\n        c_dev, c_train = sample_id(id_dict['cotton'])\n        cs_dev, cs_train = sample_id(id_dict['cotton_spandex'])\n        dev_id = c_dev + cs_dev\n        train_id = c_train + cs_train\n        dev_ds = [dataset[i] for i in dev_id]\n        train_ds = [dataset[i] for i in train_id]\n        return [d for d in sample_dataset(train_ds, num_samples, num_per_sample, balance)] + \\\n               [d for d in sample_dataset(dev_ds, num_samples, num_per_sample, balance)]", "metadata": {"trusted": true}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": "def get_models():\n    models = [\n        nn.Sequential(\n            nn.Linear(228, 512),\n            nn.Sigmoid(),\n            nn.LayerNorm(512),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.Sigmoid(),\n            nn.LayerNorm(512),\n            nn.Dropout(),\n            nn.Linear(512, 256),\n            nn.Sigmoid(),\n            nn.LayerNorm(256),\n            nn.Dropout(),\n            nn.Linear(256, 128),\n            nn.Sigmoid(),\n            nn.LayerNorm(128),\n            nn.Dropout(),\n            nn.Linear(128, 2),\n            nn.Softmax(dim=-1)\n        ) for _ in range(15)\n    ]\n    for model in models:\n        model.to(device)\n    return models\n\ndef predict_on_single_model(model, data_X):\n    data_loader = DataLoader(data_X, batch_size=512)\n    y_pred = torch.zeros(0).long().to(device)\n    model.eval()\n    with torch.no_grad():\n        for batch_X in data_loader:\n            batch_X = batch_X.to(device)\n            output = model(batch_X)\n            y_pred = torch.cat([y_pred, torch.argmax(output, dim=-1)])\n    return y_pred.cpu().numpy()\n\ndef predict(models, data_X):\n    preds = [predict_on_single_model(model, data_X) for model in models]\n    for pred in preds:\n        assert len(pred) % NUM_SAMPLES == 0\n        assert len(preds[0]) == len(pred)\n    y_pred = []\n    for k in range(0, len(preds[0]), NUM_SAMPLES):\n        a = 0\n        b = 0\n        for pred in preds:\n            a += np.sum(pred[k:k + NUM_SAMPLES] == 0)\n            b += np.sum(pred[k:k + NUM_SAMPLES] == 1)\n        assert a != b\n        y_pred.append(0 if a > b else 1)\n    return y_pred\n\ndef evaluate(models, data_X, y):\n    y_true = []\n    assert len(y) % NUM_SAMPLES == 0\n    for k in range(0, len(y), NUM_SAMPLES):\n        assert np.sum(y[k:k + NUM_SAMPLES] == y[k]) == NUM_SAMPLES\n        y_true.append(y[k])\n    y_pred = predict(models, data_X)\n    print(classification_report(y_true, y_pred, digits=4))", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "def train_single_model(model, pca_train_X, train_y, pca_dev_X, dev_y, pca_test_X, test_y):\n    n = len(pca_train_X)\n    idx = np.arange(n)\n    idx = np.random.choice(idx, size=int(n * 0.9))\n    training_set = DataLoader(list(zip(pca_train_X[idx], train_y[idx])),\n                              batch_size=512,\n                              shuffle=True)\n    optimizer = optim.Adam(model.parameters())\n    loss_fn = nn.BCELoss()\n    epoch = 0\n    best_acc, best_epoch = 0, 0\n    while epoch < 100:\n        epoch += 1\n        model.train()\n        with torch.enable_grad():\n            for batch_X, batch_y in training_set:\n                batch_X = batch_X.to(device)\n                batch_y = batch_y.to(device)\n                optimizer.zero_grad()\n                output = model(batch_X)\n                loss = loss_fn(output, torch.eye(2).to(device)[batch_y])\n                loss.backward()\n                optimizer.step()\n        acc = np.sum(predict_on_single_model(model, pca_dev_X) == dev_y)\n        if acc > best_acc:\n            best_acc = acc\n            best_epoch = epoch\n        elif epoch - best_epoch >= 10:\n            print('early stopping on epoch {}, dev acc {:.4f}'.format(epoch, acc / dev_y.shape[0]))\n            break\n    y_pred = predict_on_single_model(model, pca_test_X)\n    return np.sum(y_pred == test_y) / y_pred.shape[0]\n\ndef train():\n    models = get_models()\n    \n    dataset_train = get_data(os.path.join(data_dir, 'train.json'))\n    dataset_test = get_data(os.path.join(data_dir, 'test.json'))\n\n    train_X, train_y, dev_X, dev_y = process_dataset(dataset_train, balance=True, dev=10)\n    test_X, test_y = process_dataset(dataset_test)\n\n    del dataset_train, dataset_test\n\n    pca = PCA(n_components=228)\n    pca_train_X = pca.fit_transform(train_X)\n    pca_dev_X = pca.transform(dev_X)\n    pca_test_X = pca.transform(test_X)\n    \n    del train_X, dev_X, test_X\n    \n    print('\\nsaving PCA to: ' + pca_path)\n    with open(pca_path, 'wb') as file:\n        pickle.dump(pca, file)\n    \n    print('\\ndata preprocessed\\n\\ntraining models\\n')\n\n    for i, model in enumerate(models, start=1):\n        acc = train_single_model(model,\n                                 pca_train_X, train_y,\n                                 pca_dev_X, dev_y,\n                                 pca_test_X, test_y)\n        print(f'{i}/{len(models)} - test acc: {acc:.4f}')\n    \n    print('\\nmodels trained\\n\\nevaluating on the training set:')\n    evaluate(models, pca_train_X, train_y)\n    print('\\nevaluating on the dev set:')\n    evaluate(models, pca_dev_X, dev_y)\n    print('\\nevaluating on the test set:')\n    evaluate(models, pca_test_X, test_y)\n\n    print('\\nsaving models to ' + model_path)\n    torch.save([model.state_dict() for model in models], model_path)", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": "# training\ntrain()", "metadata": {"trusted": true}, "execution_count": 5, "outputs": [{"name": "stdout", "text": "60 60\n10 10\n25 25\n\nsaving PCA to: s3://my-modelarts-xyx-010/notebook-001/model/classifier-pca.pkl\n\ndata preprocessed\n\ntraining models\n\nearly stopping on epoch 11, dev acc 1.0000\n1/15 - test acc: 0.9624\nearly stopping on epoch 12, dev acc 1.0000\n2/15 - test acc: 0.9514\nearly stopping on epoch 11, dev acc 1.0000\n3/15 - test acc: 0.9596\nearly stopping on epoch 12, dev acc 1.0000\n4/15 - test acc: 0.9540\nearly stopping on epoch 11, dev acc 1.0000\n5/15 - test acc: 0.9302\nearly stopping on epoch 11, dev acc 1.0000\n6/15 - test acc: 0.9532\nearly stopping on epoch 12, dev acc 1.0000\n7/15 - test acc: 0.9521\nearly stopping on epoch 12, dev acc 1.0000\n8/15 - test acc: 0.9776\nearly stopping on epoch 11, dev acc 1.0000\n9/15 - test acc: 0.9423\nearly stopping on epoch 11, dev acc 1.0000\n10/15 - test acc: 0.9452\nearly stopping on epoch 12, dev acc 1.0000\n11/15 - test acc: 0.9407\nearly stopping on epoch 12, dev acc 1.0000\n12/15 - test acc: 0.9539\nearly stopping on epoch 11, dev acc 1.0000\n13/15 - test acc: 0.9582\nearly stopping on epoch 11, dev acc 1.0000\n14/15 - test acc: 0.9159\nearly stopping on epoch 11, dev acc 1.0000\n15/15 - test acc: 0.9462\n\nmodels trained\n\nevaluating on the training set:\n             precision    recall  f1-score   support\n\n          0     1.0000    1.0000    1.0000        60\n          1     1.0000    1.0000    1.0000        60\n\navg / total     1.0000    1.0000    1.0000       120\n\n\nevaluating on the dev set:\n             precision    recall  f1-score   support\n\n          0     1.0000    1.0000    1.0000        10\n          1     1.0000    1.0000    1.0000        10\n\navg / total     1.0000    1.0000    1.0000        20\n\n\nevaluating on the test set:\n             precision    recall  f1-score   support\n\n          0     1.0000    0.9200    0.9583        25\n          1     0.9259    1.0000    0.9615        25\n\navg / total     0.9630    0.9600    0.9599        50\n\n\nsaving models to s3://my-modelarts-xyx-010/notebook-001/model/classifier.pt\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "# evaluating the saved models\n\ndataset_test = get_data(os.path.join(data_dir, 'test.json'))\ntest_X, test_y = process_dataset(dataset_test)\n\ndel dataset_test\n\nprint('loading PCA from: ' + pca_path)\nwith open(pca_path, 'rb') as file:\n    pca = pickle.load(file)\n\npca_test_X = pca.transform(test_X)\n\ndel pca, test_X\n\nmodels = get_models()\nprint('loading models from: ' + model_path)\nstate_dicts = torch.load(model_path)\nassert len(state_dicts) == len(models)\nfor model, state_dict in zip(models, state_dicts):\n    model.load_state_dict(state_dict)\n\nprint('evaluating on the test set:')\nevaluate(models, pca_test_X, test_y)\n\ndel models, pca_test_X, test_y", "metadata": {"trusted": true}, "execution_count": 6, "outputs": [{"name": "stdout", "text": "25 25\nloading PCA from: s3://my-modelarts-xyx-010/notebook-001/model/classifier-pca.pkl\nloading models from: s3://my-modelarts-xyx-010/notebook-001/model/classifier.pt\nevaluating on the test set:\n             precision    recall  f1-score   support\n\n          0     1.0000    0.9200    0.9583        25\n          1     0.9259    1.0000    0.9615        25\n\navg / total     0.9630    0.9600    0.9599        50\n\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}