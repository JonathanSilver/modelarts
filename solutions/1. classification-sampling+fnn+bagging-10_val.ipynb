{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1    2\n",
      "0      1  97.0  3.0\n",
      "1      2  98.8  1.2\n",
      "2      3  97.0  3.0\n",
      "3      4  98.0  2.0\n",
      "4      5  97.5  2.5\n",
      "..   ...   ...  ...\n",
      "110  111  98.0  2.0\n",
      "111  112  97.0  3.0\n",
      "112  113  98.0  2.0\n",
      "113  114  97.0  3.0\n",
      "114  115  98.0  2.0\n",
      "\n",
      "[115 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('labels.xlsx', header=None)\n",
    "print(df)\n",
    "cotton_id2label = {str(int(df.iloc[i][0])): df.iloc[i][1] for i in range(df.index.stop)}\n",
    "spandex_id2label = {str(int(df.iloc[i][0])): df.iloc[i][2] for i in range(df.index.stop)}\n",
    "#print(cotton_id2label)\n",
    "#print(spandex_id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    res = []\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        start = False\n",
    "        for row in reader:\n",
    "            if row[0] == 'Wavelength (nm)':\n",
    "                start = True\n",
    "            elif start:\n",
    "                res.append(row)\n",
    "    return res\n",
    "\n",
    "def get_data_3(root_dir):\n",
    "    filenames = list(filter(lambda x : x.endswith('_a.csv')\n",
    "                            or x.endswith('_i.csv')\n",
    "                            or x.endswith('_r.csv'),\n",
    "                            os.listdir(root_dir)))\n",
    "    filenames = [(filename, filename[7:-6]) for filename in filenames]\n",
    "    id2file = {file_id: [] for _, file_id in filenames}\n",
    "    for filename, file_id in filenames:\n",
    "        id2file[file_id].append(filename)\n",
    "#     print(id2file)\n",
    "#     id2feat = {}\n",
    "#     if len(id2file) != 20:\n",
    "#         print(str(len(id2file)) + ' ' + str(root_dir))\n",
    "#         return False, False\n",
    "#     res = np.zeros((228, 4), dtype=np.float32)\n",
    "    res = []\n",
    "    for file_id, filenames in id2file.items():\n",
    "        feat = {}\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('_a.csv'):\n",
    "                feat['a'] = process_file(os.path.join(root_dir, filename))\n",
    "            elif filename.endswith('_i.csv'):\n",
    "                feat['i'] = process_file(os.path.join(root_dir, filename))\n",
    "            elif filename.endswith('_r.csv'):\n",
    "                feat['r'] = process_file(os.path.join(root_dir, filename))\n",
    "            else:\n",
    "                assert False\n",
    "        column0a = [col0 for col0, _ in feat['a']]\n",
    "        column0i = [col0 for col0, _ in feat['i']]\n",
    "        column0r = [col0 for col0, _ in feat['r']]\n",
    "        assert column0a == column0i \\\n",
    "               and column0a == column0r\n",
    "        column1a = [col1 for _, col1 in feat['a']]\n",
    "        column1i = [col1 for _, col1 in feat['i']]\n",
    "        column1r = [col1 for _, col1 in feat['r']]\n",
    "        feat = list(zip(column0a, column1a, column1i, column1r))\n",
    "#         print(feat)\n",
    "#         res += np.array(feat, dtype=np.float32)\n",
    "        res.append(np.array(feat, dtype=np.float32))\n",
    "#         break\n",
    "#     assert len(res) == 20\n",
    "    return True, res\n",
    "\n",
    "def get_data_2(root_dir, name):\n",
    "    dataset = []\n",
    "    for sub_dir in os.listdir(root_dir):\n",
    "#         print(name, sub_dir)\n",
    "#         print(id2feat)\n",
    "        record = {}\n",
    "        record['name'] = name\n",
    "        record['label'] = cotton_id2label[sub_dir] \\\n",
    "                    if name == 'cotton' \\\n",
    "                    else spandex_id2label[sub_dir]\n",
    "        res, feat = get_data_3(os.path.join(root_dir, sub_dir))\n",
    "        if res:\n",
    "            record['feat'] = feat\n",
    "            dataset.append(record)\n",
    "#             print(record['feat'][0].shape)\n",
    "#             break\n",
    "    return dataset\n",
    "\n",
    "def get_data(root_dir):\n",
    "    dataset0 = get_data_2(os.path.join(root_dir, 'cotton'), 'cotton')\n",
    "    dataset1 = get_data_2(os.path.join(root_dir, 'cotton_spandex'), 'cotton_spandex')\n",
    "#     column0 = [col0 for col0, _, _, _ in dataset0[0]['feat']]\n",
    "    return dataset0 + dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "dataset_train = get_data('train')\n",
    "dataset_test  = get_data('test')\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_feats(feats, num):\n",
    "    idx = np.arange(len(feats))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    assert len(idx) == num\n",
    "    return np.sum(feats[idx], axis=0) / num\n",
    "\n",
    "def sample_from_record(record, num_per_sample, X, y):\n",
    "    X.append(sample_feats(record['feats'], num_per_sample).reshape(-1))\n",
    "    y.append(0 if record['name'] == 'cotton' else 1)\n",
    "\n",
    "def repetitive_sample_from_record(record, num_samples, num_per_sample, X, y):\n",
    "    [\n",
    "        sample_from_record(record, num_per_sample, X, y)\n",
    "        for _ in range(num_samples)\n",
    "    ]\n",
    "\n",
    "def get_id_dict(dataset):\n",
    "    id_dict = {'cotton': [], 'cotton_spandex': []}\n",
    "    for i, record in enumerate(dataset):\n",
    "        id_dict[record['name']].append(i)\n",
    "    return id_dict\n",
    "\n",
    "def sample_dataset(dataset, num_samples, num_per_sample, balance):\n",
    "    id_dict = get_id_dict(dataset)\n",
    "    X = []\n",
    "    y = []\n",
    "    for record in dataset:\n",
    "        repetitive_sample_from_record(record, num_samples, num_per_sample, X, y)\n",
    "    a = len(id_dict['cotton'])\n",
    "    b = len(id_dict['cotton_spandex']) * 1.0\n",
    "    b = int(b)\n",
    "    print(a, b)\n",
    "    if balance and a != b:\n",
    "        if a > b:\n",
    "            diff = a - b\n",
    "            idx = np.arange(b)\n",
    "            name = 'cotton_spandex'\n",
    "        else:  # b > a\n",
    "            diff = b - a\n",
    "            idx = np.arange(a)\n",
    "            name = 'cotton'\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:diff]\n",
    "        [\n",
    "            repetitive_sample_from_record(\n",
    "                dataset[id_dict[name][i]],\n",
    "                num_samples, num_per_sample, X, y\n",
    "            ) for i in idx\n",
    "        ]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def process_dataset(dataset, num_samples=2001, num_per_sample=15, balance=False, dev=0):\n",
    "    id_dict = get_id_dict(dataset)\n",
    "    for record in dataset:\n",
    "        feats = np.array(record['feat'])\n",
    "#         assert len(feats) == 20\n",
    "        feats2 = []\n",
    "        for feat in feats:\n",
    "            feat[:, 0] /= 1800\n",
    "            feat[:, 2] /= 500000\n",
    "            feat = feat[:, 1:]\n",
    "            feats2.append(feat)\n",
    "        feats = np.array(feats2)\n",
    "        record['feats'] = feats  # not `feat`\n",
    "#         print(np.min(feats), np.max(feats))\n",
    "    \n",
    "    if dev == 0:  # no dev set\n",
    "        return sample_dataset(dataset, num_samples, num_per_sample, balance)\n",
    "    else:\n",
    "        def sample_id(id_list):\n",
    "            idx = np.arange(len(id_list))\n",
    "            np.random.shuffle(idx)\n",
    "            return [id_list[i] for i in idx[:dev]], [id_list[i] for i in idx[dev:]]\n",
    "        c_dev, c_train = sample_id(id_dict['cotton'])\n",
    "        cs_dev, cs_train = sample_id(id_dict['cotton_spandex'])\n",
    "        dev_id = c_dev + cs_dev\n",
    "        train_id = c_train + cs_train\n",
    "        dev_ds = [dataset[i] for i in dev_id]\n",
    "        train_ds = [dataset[i] for i in train_id]\n",
    "        return *sample_dataset(train_ds, num_samples, num_per_sample, balance), \\\n",
    "               *sample_dataset(dev_ds, num_samples, num_per_sample, balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n",
      "10 10\n",
      "25 25\n",
      "120060 120060\n",
      "20010 20010\n",
      "50025 50025\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "train_X, train_y, dev_X, dev_y = process_dataset(dataset_train, balance=True, dev=10)\n",
    "test_X, test_y = process_dataset(dataset_test)\n",
    "\n",
    "print(np.sum(train_y == 0), np.sum(train_y == 1))\n",
    "print(np.sum(dev_y == 0), np.sum(dev_y == 1))\n",
    "print(np.sum(test_y == 0), np.sum(test_y == 1))\n",
    "\n",
    "pca = PCA(n_components=228)\n",
    "pca_train_X = pca.fit_transform(train_X)\n",
    "pca_dev_X = pca.transform(dev_X)\n",
    "pca_test_X = pca.transform(test_X)\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = [tf.keras.Sequential([\n",
    "        layers.Dense(512, activation=tf.sigmoid),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation=tf.sigmoid),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation=tf.sigmoid),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation=tf.sigmoid),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2),\n",
    "        layers.Softmax()\n",
    "    ]) for _ in range(15)]\n",
    "\n",
    "    for model in models:\n",
    "        model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                      loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',\n",
    "                                                 patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "        n = len(pca_train_X)\n",
    "        idx = np.arange(n)\n",
    "        idx = np.random.choice(idx, size=int(n * 0.9))\n",
    "\n",
    "        model.fit(pca_train_X[idx], train_y[idx],\n",
    "                  callbacks=[callback],\n",
    "                  batch_size=512,\n",
    "                  epochs=100,\n",
    "                  verbose=0,\n",
    "                  validation_data=(pca_dev_X, dev_y))\n",
    "\n",
    "        model.evaluate(pca_test_X, test_y, verbose=2)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_pred(models, X):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        pred = model(X).numpy()\n",
    "        preds.append(np.argmax(pred, axis=-1))\n",
    "    return preds\n",
    "\n",
    "def evaluate(preds, y):\n",
    "    group = 2001\n",
    "    for pred in preds:\n",
    "        assert len(pred) % group == 0\n",
    "        assert len(preds[0]) == len(pred)\n",
    "        # print(len(pred))\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for k in range(0, len(preds[0]), group):\n",
    "        assert np.sum(y[k:k + group] == y[k]) == group\n",
    "        y_true.append(y[k])\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for pred in preds:\n",
    "            a += np.sum(pred[k:k + group] == 0)\n",
    "            b += np.sum(pred[k:k + group] == 1)\n",
    "        assert a != b\n",
    "        y_pred.append(0 if a > b else 1)\n",
    "    print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0:\n",
      "3127/3127 - 4s - loss: 0.3523 - sparse_categorical_accuracy: 0.9597\n",
      "3127/3127 - 4s - loss: 0.3543 - sparse_categorical_accuracy: 0.9497\n",
      "3127/3127 - 3s - loss: 0.3462 - sparse_categorical_accuracy: 0.9369\n",
      "3127/3127 - 3s - loss: 0.3478 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.4241 - sparse_categorical_accuracy: 0.9544\n",
      "3127/3127 - 3s - loss: 0.3347 - sparse_categorical_accuracy: 0.9420\n",
      "3127/3127 - 3s - loss: 0.3933 - sparse_categorical_accuracy: 0.9479\n",
      "3127/3127 - 3s - loss: 0.2926 - sparse_categorical_accuracy: 0.9545\n",
      "3127/3127 - 3s - loss: 0.4401 - sparse_categorical_accuracy: 0.9377\n",
      "3127/3127 - 3s - loss: 0.4077 - sparse_categorical_accuracy: 0.9403\n",
      "3127/3127 - 3s - loss: 0.3442 - sparse_categorical_accuracy: 0.9559\n",
      "3127/3127 - 3s - loss: 0.3394 - sparse_categorical_accuracy: 0.9584\n",
      "3127/3127 - 3s - loss: 0.3734 - sparse_categorical_accuracy: 0.9597\n",
      "3127/3127 - 3s - loss: 0.3611 - sparse_categorical_accuracy: 0.9593\n",
      "3127/3127 - 3s - loss: 0.3761 - sparse_categorical_accuracy: 0.9595\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 1:\n",
      "3127/3127 - 3s - loss: 0.3625 - sparse_categorical_accuracy: 0.9578\n",
      "3127/3127 - 3s - loss: 0.3821 - sparse_categorical_accuracy: 0.9399\n",
      "3127/3127 - 3s - loss: 0.4811 - sparse_categorical_accuracy: 0.9386\n",
      "3127/3127 - 3s - loss: 0.3457 - sparse_categorical_accuracy: 0.9365\n",
      "3127/3127 - 3s - loss: 0.6005 - sparse_categorical_accuracy: 0.8988\n",
      "3127/3127 - 3s - loss: 0.3560 - sparse_categorical_accuracy: 0.9600\n",
      "3127/3127 - 3s - loss: 0.4163 - sparse_categorical_accuracy: 0.9196\n",
      "3127/3127 - 3s - loss: 0.3408 - sparse_categorical_accuracy: 0.9561\n",
      "3127/3127 - 3s - loss: 0.3742 - sparse_categorical_accuracy: 0.9480\n",
      "3127/3127 - 3s - loss: 0.4081 - sparse_categorical_accuracy: 0.9347\n",
      "3127/3127 - 3s - loss: 0.3199 - sparse_categorical_accuracy: 0.9585\n",
      "3127/3127 - 3s - loss: 0.3395 - sparse_categorical_accuracy: 0.9590\n",
      "3127/3127 - 3s - loss: 0.3618 - sparse_categorical_accuracy: 0.9579\n",
      "3127/3127 - 3s - loss: 0.3551 - sparse_categorical_accuracy: 0.9491\n",
      "3127/3127 - 3s - loss: 0.4093 - sparse_categorical_accuracy: 0.9338\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 2:\n",
      "3127/3127 - 3s - loss: 0.3376 - sparse_categorical_accuracy: 0.9540\n",
      "3127/3127 - 3s - loss: 0.3472 - sparse_categorical_accuracy: 0.9594\n",
      "3127/3127 - 3s - loss: 0.3686 - sparse_categorical_accuracy: 0.9531\n",
      "3127/3127 - 3s - loss: 0.4179 - sparse_categorical_accuracy: 0.9239\n",
      "3127/3127 - 3s - loss: 0.3123 - sparse_categorical_accuracy: 0.9523\n",
      "3127/3127 - 3s - loss: 0.3750 - sparse_categorical_accuracy: 0.9409\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3127/3127 - 3s - loss: 0.3364 - sparse_categorical_accuracy: 0.9599\n",
      "3127/3127 - 3s - loss: 0.3934 - sparse_categorical_accuracy: 0.9420\n",
      "3127/3127 - 3s - loss: 0.3400 - sparse_categorical_accuracy: 0.9587\n",
      "3127/3127 - 3s - loss: 0.3493 - sparse_categorical_accuracy: 0.9451\n",
      "3127/3127 - 3s - loss: 0.3444 - sparse_categorical_accuracy: 0.9599\n",
      "3127/3127 - 3s - loss: 0.3719 - sparse_categorical_accuracy: 0.9557\n",
      "3127/3127 - 3s - loss: 0.3640 - sparse_categorical_accuracy: 0.9582\n",
      "3127/3127 - 3s - loss: 0.4367 - sparse_categorical_accuracy: 0.9400\n",
      "3127/3127 - 3s - loss: 0.4156 - sparse_categorical_accuracy: 0.9359\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 3:\n",
      "3127/3127 - 3s - loss: 0.3424 - sparse_categorical_accuracy: 0.9564\n",
      "3127/3127 - 3s - loss: 0.3758 - sparse_categorical_accuracy: 0.9456\n",
      "3127/3127 - 3s - loss: 0.3653 - sparse_categorical_accuracy: 0.9586\n",
      "3127/3127 - 3s - loss: 0.3571 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.3390 - sparse_categorical_accuracy: 0.9501\n",
      "3127/3127 - 3s - loss: 0.3482 - sparse_categorical_accuracy: 0.9579\n",
      "3127/3127 - 3s - loss: 0.4316 - sparse_categorical_accuracy: 0.9392\n",
      "3127/3127 - 3s - loss: 0.3345 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.4714 - sparse_categorical_accuracy: 0.9071\n",
      "3127/3127 - 3s - loss: 0.4649 - sparse_categorical_accuracy: 0.9282\n",
      "3127/3127 - 3s - loss: 0.3326 - sparse_categorical_accuracy: 0.9577\n",
      "3127/3127 - 3s - loss: 0.3398 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.3746 - sparse_categorical_accuracy: 0.9503\n",
      "3127/3127 - 3s - loss: 0.4128 - sparse_categorical_accuracy: 0.9400\n",
      "3127/3127 - 3s - loss: 0.3955 - sparse_categorical_accuracy: 0.9384\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 4:\n",
      "3127/3127 - 3s - loss: 0.3409 - sparse_categorical_accuracy: 0.9576\n",
      "3127/3127 - 3s - loss: 0.3624 - sparse_categorical_accuracy: 0.9484\n",
      "3127/3127 - 3s - loss: 0.3458 - sparse_categorical_accuracy: 0.9585\n",
      "3127/3127 - 3s - loss: 0.3119 - sparse_categorical_accuracy: 0.9543\n",
      "3127/3127 - 3s - loss: 0.3721 - sparse_categorical_accuracy: 0.9577\n",
      "3127/3127 - 3s - loss: 0.3554 - sparse_categorical_accuracy: 0.9574\n",
      "3127/3127 - 3s - loss: 0.3909 - sparse_categorical_accuracy: 0.9578\n",
      "3127/3127 - 3s - loss: 0.3027 - sparse_categorical_accuracy: 0.9578\n",
      "3127/3127 - 3s - loss: 0.3477 - sparse_categorical_accuracy: 0.9444\n",
      "3127/3127 - 3s - loss: 0.3655 - sparse_categorical_accuracy: 0.9473\n",
      "3127/3127 - 3s - loss: 0.3875 - sparse_categorical_accuracy: 0.9527\n",
      "3127/3127 - 3s - loss: 0.3343 - sparse_categorical_accuracy: 0.9598\n",
      "3127/3127 - 3s - loss: 0.4636 - sparse_categorical_accuracy: 0.9227\n",
      "3127/3127 - 3s - loss: 0.3410 - sparse_categorical_accuracy: 0.9456\n",
      "3127/3127 - 3s - loss: 0.3837 - sparse_categorical_accuracy: 0.9456\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 5:\n",
      "3127/3127 - 3s - loss: 0.4849 - sparse_categorical_accuracy: 0.9227\n",
      "3127/3127 - 3s - loss: 0.3379 - sparse_categorical_accuracy: 0.9581\n",
      "3127/3127 - 3s - loss: 0.3497 - sparse_categorical_accuracy: 0.9463\n",
      "3127/3127 - 3s - loss: 0.3599 - sparse_categorical_accuracy: 0.9434\n",
      "3127/3127 - 3s - loss: 0.3585 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.3572 - sparse_categorical_accuracy: 0.9539\n",
      "3127/3127 - 3s - loss: 0.3554 - sparse_categorical_accuracy: 0.9591\n",
      "3127/3127 - 3s - loss: 0.3802 - sparse_categorical_accuracy: 0.9334\n",
      "3127/3127 - 3s - loss: 0.4271 - sparse_categorical_accuracy: 0.9297\n",
      "3127/3127 - 3s - loss: 0.3799 - sparse_categorical_accuracy: 0.9516\n",
      "3127/3127 - 3s - loss: 0.3594 - sparse_categorical_accuracy: 0.9577\n",
      "3127/3127 - 3s - loss: 0.3623 - sparse_categorical_accuracy: 0.9583\n",
      "3127/3127 - 3s - loss: 0.3377 - sparse_categorical_accuracy: 0.9451\n",
      "3127/3127 - 3s - loss: 0.3745 - sparse_categorical_accuracy: 0.9462\n",
      "3127/3127 - 3s - loss: 0.4365 - sparse_categorical_accuracy: 0.9400\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 6:\n",
      "3127/3127 - 3s - loss: 0.3183 - sparse_categorical_accuracy: 0.9599\n",
      "3127/3127 - 3s - loss: 0.2998 - sparse_categorical_accuracy: 0.9599\n",
      "3127/3127 - 3s - loss: 0.4109 - sparse_categorical_accuracy: 0.9405\n",
      "3127/3127 - 3s - loss: 0.4064 - sparse_categorical_accuracy: 0.9393\n",
      "3127/3127 - 3s - loss: 0.3634 - sparse_categorical_accuracy: 0.9486\n",
      "3127/3127 - 3s - loss: 0.3442 - sparse_categorical_accuracy: 0.9491\n",
      "3127/3127 - 3s - loss: 0.3319 - sparse_categorical_accuracy: 0.9600\n",
      "3127/3127 - 3s - loss: 0.3028 - sparse_categorical_accuracy: 0.9598\n",
      "3127/3127 - 3s - loss: 0.3702 - sparse_categorical_accuracy: 0.9481\n",
      "3127/3127 - 4s - loss: 0.3424 - sparse_categorical_accuracy: 0.9572\n",
      "3127/3127 - 4s - loss: 0.3624 - sparse_categorical_accuracy: 0.9465\n",
      "3127/3127 - 4s - loss: 0.4639 - sparse_categorical_accuracy: 0.9278\n",
      "3127/3127 - 3s - loss: 0.3571 - sparse_categorical_accuracy: 0.9404\n",
      "3127/3127 - 3s - loss: 0.4226 - sparse_categorical_accuracy: 0.9271\n",
      "3127/3127 - 3s - loss: 0.3353 - sparse_categorical_accuracy: 0.9559\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 7:\n",
      "3127/3127 - 3s - loss: 0.3719 - sparse_categorical_accuracy: 0.9495\n",
      "3127/3127 - 3s - loss: 0.4271 - sparse_categorical_accuracy: 0.9395\n",
      "3127/3127 - 3s - loss: 0.3685 - sparse_categorical_accuracy: 0.9545\n",
      "3127/3127 - 3s - loss: 0.3519 - sparse_categorical_accuracy: 0.9586\n",
      "3127/3127 - 3s - loss: 0.3442 - sparse_categorical_accuracy: 0.9598\n",
      "3127/3127 - 3s - loss: 0.3386 - sparse_categorical_accuracy: 0.9590\n",
      "3127/3127 - 3s - loss: 0.3523 - sparse_categorical_accuracy: 0.9458\n",
      "3127/3127 - 3s - loss: 0.3381 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.3767 - sparse_categorical_accuracy: 0.9550\n",
      "3127/3127 - 3s - loss: 0.3070 - sparse_categorical_accuracy: 0.9538\n",
      "3127/3127 - 3s - loss: 0.3860 - sparse_categorical_accuracy: 0.9498\n",
      "3127/3127 - 3s - loss: 0.3416 - sparse_categorical_accuracy: 0.9571\n",
      "3127/3127 - 3s - loss: 0.5055 - sparse_categorical_accuracy: 0.9291\n",
      "3127/3127 - 3s - loss: 0.4031 - sparse_categorical_accuracy: 0.9432\n",
      "3127/3127 - 3s - loss: 0.3931 - sparse_categorical_accuracy: 0.9594\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n",
      "round 8:\n",
      "3127/3127 - 3s - loss: 0.5026 - sparse_categorical_accuracy: 0.9292\n",
      "3127/3127 - 3s - loss: 0.2841 - sparse_categorical_accuracy: 0.9597\n",
      "3127/3127 - 3s - loss: 0.4185 - sparse_categorical_accuracy: 0.9397\n",
      "3127/3127 - 3s - loss: 0.4514 - sparse_categorical_accuracy: 0.9284\n",
      "3127/3127 - 3s - loss: 0.3672 - sparse_categorical_accuracy: 0.9425\n",
      "3127/3127 - 3s - loss: 0.3869 - sparse_categorical_accuracy: 0.9598\n",
      "3127/3127 - 3s - loss: 0.3817 - sparse_categorical_accuracy: 0.9401\n",
      "3127/3127 - 3s - loss: 0.4710 - sparse_categorical_accuracy: 0.9397\n",
      "3127/3127 - 3s - loss: 0.3710 - sparse_categorical_accuracy: 0.9547\n",
      "3127/3127 - 3s - loss: 0.3935 - sparse_categorical_accuracy: 0.9582\n",
      "3127/3127 - 3s - loss: 0.3804 - sparse_categorical_accuracy: 0.9413\n",
      "3127/3127 - 3s - loss: 0.3100 - sparse_categorical_accuracy: 0.9571\n",
      "3127/3127 - 3s - loss: 0.3868 - sparse_categorical_accuracy: 0.9361\n",
      "3127/3127 - 3s - loss: 0.3551 - sparse_categorical_accuracy: 0.9426\n",
      "3127/3127 - 3s - loss: 0.3651 - sparse_categorical_accuracy: 0.9589\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8800    0.9362        25\n",
      "           1     0.8929    1.0000    0.9434        25\n",
      "\n",
      "    accuracy                         0.9400        50\n",
      "   macro avg     0.9464    0.9400    0.9398        50\n",
      "weighted avg     0.9464    0.9400    0.9398        50\n",
      "\n",
      "round 9:\n",
      "3127/3127 - 3s - loss: 0.3945 - sparse_categorical_accuracy: 0.9400\n",
      "3127/3127 - 3s - loss: 0.3539 - sparse_categorical_accuracy: 0.9577\n",
      "3127/3127 - 3s - loss: 0.3890 - sparse_categorical_accuracy: 0.9411\n",
      "3127/3127 - 3s - loss: 0.3622 - sparse_categorical_accuracy: 0.9595\n",
      "3127/3127 - 3s - loss: 0.4316 - sparse_categorical_accuracy: 0.9381\n",
      "3127/3127 - 3s - loss: 0.3966 - sparse_categorical_accuracy: 0.9375\n",
      "3127/3127 - 3s - loss: 0.3294 - sparse_categorical_accuracy: 0.9513\n",
      "3127/3127 - 3s - loss: 0.4163 - sparse_categorical_accuracy: 0.9373\n",
      "3127/3127 - 3s - loss: 0.3172 - sparse_categorical_accuracy: 0.9566\n",
      "3127/3127 - 3s - loss: 0.3378 - sparse_categorical_accuracy: 0.9591\n",
      "3127/3127 - 4s - loss: 0.4332 - sparse_categorical_accuracy: 0.9194\n",
      "3127/3127 - 4s - loss: 0.3151 - sparse_categorical_accuracy: 0.9509\n",
      "3127/3127 - 4s - loss: 0.3499 - sparse_categorical_accuracy: 0.9585\n",
      "3127/3127 - 4s - loss: 0.3144 - sparse_categorical_accuracy: 0.9396\n",
      "3127/3127 - 4s - loss: 0.3706 - sparse_categorical_accuracy: 0.9571\n",
      "training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        60\n",
      "           1     1.0000    1.0000    1.0000        60\n",
      "\n",
      "    accuracy                         1.0000       120\n",
      "   macro avg     1.0000    1.0000    1.0000       120\n",
      "weighted avg     1.0000    1.0000    1.0000       120\n",
      "\n",
      "------------------------------\n",
      "dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        10\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        20\n",
      "   macro avg     1.0000    1.0000    1.0000        20\n",
      "weighted avg     1.0000    1.0000    1.0000        20\n",
      "\n",
      "------------------------------\n",
      "test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9200    0.9583        25\n",
      "           1     0.9259    1.0000    0.9615        25\n",
      "\n",
      "    accuracy                         0.9600        50\n",
      "   macro avg     0.9630    0.9600    0.9599        50\n",
      "weighted avg     0.9630    0.9600    0.9599        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "num_tests = 10\n",
    "\n",
    "for i in range(num_tests):\n",
    "    print(f'round {i}:')\n",
    "    models = get_models()\n",
    "    print('training set:')\n",
    "    evaluate(get_pred(models, pca_train_X), train_y)\n",
    "    print('-' * 30 + '\\ndev set:')\n",
    "    evaluate(get_pred(models, pca_dev_X), dev_y)\n",
    "    print('-' * 30 + '\\ntest set:')\n",
    "    evaluate(get_pred(models, pca_test_X), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
